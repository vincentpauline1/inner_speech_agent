{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1f0aae-0ad2-4a21-b363-e92dc7a1c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current path: /mnt/c/Users/vpaul/OneDrive - CentraleSupelec/Inner_Speech/agent/imitative_agent\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as ipw\n",
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from imitative_agent import ImitativeAgent\n",
    "from lib.dataset_wrapper import Dataset\n",
    "from lib import utils\n",
    "from lib import abx_utils\n",
    "from lib import notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5e19cb-778d-4ddb-b31d-d67db98a1bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n"
     ]
    }
   ],
   "source": [
    "agents_path = glob(\"../out/imitative_agent/*/\")\n",
    "agents_path.sort()\n",
    "\n",
    "agents_alias = {}\n",
    "agents_group = {}\n",
    "\n",
    "for agent_path in agents_path:\n",
    "    agent = ImitativeAgent.reload(agent_path, load_nn=False)\n",
    "    config = agent.config\n",
    "        \n",
    "    agent_i = agent_path[-2]\n",
    "    agent_alias = \" \".join((\n",
    "        f\"{','.join(config['dataset']['names'])}\",\n",
    "        f\"synth_art={agent.synthesizer.config['dataset']['art_type']}\",\n",
    "        f\"jerk_c={config['training']['jerk_loss_ceil']}\",\n",
    "        f\"jerk_w={config['training']['jerk_loss_weight']}\",\n",
    "        f\"bi={config['model']['inverse_model']['bidirectional']}\",\n",
    "        f\"({agent_i})\",\n",
    "    ))\n",
    "    agents_alias[agent_alias] = agent_path\n",
    "    \n",
    "    agent_group = \" \".join((\n",
    "        f\"{','.join(config['dataset']['names'])}\",\n",
    "        f\"synth_art={agent.synthesizer.config['dataset']['art_type']}\",\n",
    "        f\"jerk_c={config['training']['jerk_loss_ceil']}\",\n",
    "        f\"jerk_w={config['training']['jerk_loss_weight']}\",\n",
    "        f\"bi={config['model']['inverse_model']['bidirectional']}\",\n",
    "    ))\n",
    "    if agent_group not in agents_group:\n",
    "        agents_group[agent_group] = []\n",
    "    agents_group[agent_group].append(agent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c5fb8b-4cbf-47d1-bc6d-485a00b2edfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2003b51cdc04bd68738302b4581351f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "Error processing agent pb2007,pb2007_speedx2 synth_art=art_params jerk_c=0.014 jerk_w=1 bi=True (0): 'pb2007_speedx2'\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "Error processing agent pb2007,pb2007_speedx2 synth_art=art_params jerk_c=0.014 jerk_w=1 bi=True (1): 'pb2007_speedx2'\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "Error processing agent pb2007,pb2007_speedx2 synth_art=art_params jerk_c=0.014 jerk_w=1 bi=True (2): 'pb2007_speedx2'\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "Error processing agent pb2007,pb2007_speedx2 synth_art=art_params jerk_c=0.014 jerk_w=1 bi=True (3): 'pb2007_speedx2'\n",
      "{'dataset': {'batch_size': 8, 'datasplits_size': [64, 16, 20], 'names': ['pb2007', 'pb2007_speedx2'], 'num_workers': 6, 'shuffle_between_epochs': True, 'sound_type': 'cepstrum'}, 'model': {'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}, 'synthesizer': {'name': 'ea587b76c95fecef01cfd16c7f5f289d-0/'}, 'training': {'jerk_loss_ceil': 0.014, 'jerk_loss_weight': 1, 'learning_rate': 0.001, 'max_epochs': 500, 'patience': 25}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "{'direct_model': {'activation': 'relu', 'batch_norm': True, 'dropout_p': 0.25, 'hidden_layers': [256, 256, 256, 256]}, 'inverse_model': {'bidirectional': True, 'dropout_p': 0.25, 'hidden_size': 32, 'num_layers': 2}}\n",
      "Error processing agent pb2007,pb2007_speedx2 synth_art=art_params jerk_c=0.014 jerk_w=1 bi=True (4): 'pb2007_speedx2'\n"
     ]
    }
   ],
   "source": [
    "# Load cached occlusions metrics or initialize empty dict if not exists\n",
    "agents_occlusions_metrics = utils.pickle_load(\"../out/imitative_agent/occlusions_cache.pickle\", {})\n",
    "\n",
    "for agent_alias, agent_path in tqdm(agents_alias.items()):\n",
    "    # Skip if agent already processed\n",
    "    if agent_path in agents_occlusions_metrics: continue\n",
    "    \n",
    "    try:\n",
    "        # Load agent and get datasets\n",
    "        agent = ImitativeAgent.reload(agent_path)\n",
    "        synth_dataset = agent.synthesizer.dataset\n",
    "        main_dataset = agent.get_main_dataset()\n",
    "        agent_lab = agent.get_datasplit_lab(2)\n",
    "        agent_features = agent.repeat_datasplit(2)\n",
    "        \n",
    "        # Process each dataset's estimated EMA features\n",
    "        datasets_estimated_ema = {}\n",
    "        for dataset_name, dataset_features in agent_features.items():\n",
    "            try:\n",
    "                datasets_estimated_ema[dataset_name] = {}\n",
    "                items_estimated_ema = datasets_estimated_ema[dataset_name]\n",
    "                \n",
    "                # Convert articulatory features to EMA for each item\n",
    "                items_estimated_art = dataset_features[\"art_estimated\"]\n",
    "                for item_name, item_estimated_art in items_estimated_art.items():\n",
    "                    item_estimated_ema = synth_dataset.art_to_ema(item_estimated_art)\n",
    "                    items_estimated_ema[item_name] = item_estimated_ema\n",
    "                    \n",
    "            except Exception as e:\n",
    "                # If a dataset fails, log error and continue with next dataset\n",
    "                print(f\"Error processing dataset {dataset_name}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        # Calculate occlusion metrics using successfully processed datasets\n",
    "        palate = synth_dataset.palate\n",
    "        consonants = main_dataset.phones_infos[\"consonants\"]\n",
    "        vowels = main_dataset.phones_infos[\"vowels\"]\n",
    "        consonants_indexes = abx_utils.get_datasets_phones_indexes(agent_lab, consonants, vowels)\n",
    "        agent_occlusions_metrics = abx_utils.get_occlusions_metrics(consonants, consonants_indexes, datasets_estimated_ema, palate)\n",
    "        \n",
    "        # Cache results\n",
    "        agents_occlusions_metrics[agent_path] = agent_occlusions_metrics\n",
    "        utils.pickle_dump(\"../out/imitative_agent/occlusions_cache.pickle\", agents_occlusions_metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # If an agent fails entirely, log error and continue with next agent\n",
    "        print(f\"Error processing agent {agent_alias}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22e4695-2f9d-4c6e-a234-bb55a677660e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f23b0f753534ff7ae8ccc13a3961eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='agent_alias', options=('pb2007,pb2007_speedx2 synth_art=art_params…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_agent(agent_alias):\n",
    "    agent_path = agents_alias[agent_alias]\n",
    "    agent = ImitativeAgent.reload(agent_path, load_nn=False)\n",
    "    synth_dataset = agent.synthesizer.dataset\n",
    "    palate = synth_dataset.palate\n",
    "    \n",
    "    agent_occlusions_metrics = agents_occlusions_metrics[agent_path]\n",
    "    notebooks.show_occlusions_metrics(agent_occlusions_metrics, palate)\n",
    "\n",
    "ipw.interactive(show_agent, agent_alias=sorted(agents_alias.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f8de09-8021-4f02-ae1a-8e3274106577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1833cedcfd04045862db85fcdf7cbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='agent_group_name', options=('pb2007,pb2007_speedx2 synth_art=art_p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_group(agent_group_name):\n",
    "    agent_group = agents_group[agent_group_name]\n",
    "    agent = ImitativeAgent.reload(agent_group[0], load_nn=False)\n",
    "    synth_dataset = agent.synthesizer.dataset\n",
    "    palate = synth_dataset.palate\n",
    "    \n",
    "    phones = list(agents_occlusions_metrics[agent_group[0]].keys())\n",
    "    distances = [\"tongue_tip\", \"tongue_mid\"]\n",
    "    \n",
    "    def show_phone(phone):\n",
    "        plt.figure(dpi=120)\n",
    "        \n",
    "        for i_distance, distance in enumerate(distances):\n",
    "            agents_phone_ema = []\n",
    "            for agent_path in agent_group:\n",
    "                phone_occlusions_metrics = agents_occlusions_metrics[agent_path][phone]\n",
    "                agent_phone_ema = phone_occlusions_metrics[\"min_%s_ema\" % distance]\n",
    "                agents_phone_ema.append(agent_phone_ema)\n",
    "            agents_phone_ema = np.concatenate(agents_phone_ema, axis=0)\n",
    "            \n",
    "            ax = plt.subplot(2, 1, 1 + i_distance, aspect=\"equal\")\n",
    "            ax.plot(palate[:, 0], palate[:, 1])\n",
    "            ax.scatter(agents_phone_ema[:, 0::2], agents_phone_ema[:, 1::2], s=1)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    ipw.interact(show_phone, phone=phones)\n",
    "    \n",
    "\n",
    "ipw.interactive(show_group, agent_group_name=sorted(agents_group.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47802e7-cd60-4116-8dd5-a21e5af237b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
